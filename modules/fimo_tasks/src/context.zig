const std = @import("std");
const Allocator = std.mem.Allocator;
const builtin = @import("builtin");

pub const StackInfo = extern struct {
    start: [*]u8,
    reserved_size: usize,
    commited_size: usize,

    pub fn forSlice(memory: []u8) StackInfo {
        return .{
            .start = memory.ptr + memory.len,
            .reserved_size = memory.len,
            .commited_size = memory.len,
        };
    }

    pub fn forStack(stack: Stack) StackInfo {
        if (builtin.os.tag == .windows) {
            return .{
                .start = stack.memory.ptr + stack.memory.len,
                .reserved_size = stack.memory.len,
                .commited_size = stack.commited_size,
            };
        } else {
            return .forSlice(stack.memory);
        }
    }
};

/// State of execution.
pub const Context = extern struct {
    ptr: *Impl,

    // Constructs a new context with the given stack and entry point.
    pub fn init(info: StackInfo, enter: *const fn (t: Transfer) callconv(.c) noreturn) Context {
        const ptr = Impl.init(info, enter);
        return .{ .ptr = ptr };
    }

    /// Yields control to the context and passes `data` to it.
    pub fn yieldTo(self: Context, data: usize) Transfer {
        return self.ptr.yieldTo(data);
    }

    /// Yields control to the context and passes `data` to it.
    ///
    /// The function `on_top` is invoked after the context switch.
    pub fn yieldToOnTop(
        self: Context,
        data: usize,
        on_top: fn (t: Transfer) callconv(.c) Transfer,
    ) Transfer {
        self.ptr.yieldToOnTop(data, on_top);
    }
};

const Impl = switch (builtin.target.os.tag) {
    .windows => switch (builtin.target.cpu.arch) {
        .aarch64 => WindowsContextAarch64,
        .x86_64 => WindowsContextX86_64,
        else => @compileError("unsupported platform"),
    },
    else => BoostContext,
};

const BoostContext = opaque {
    extern fn make_fcontext(
        stack_pointer: [*]u8,
        stack_size: usize,
        f: *const fn (t: Transfer) callconv(.c) noreturn,
    ) callconv(.c) *BoostContext;

    extern fn jump_fcontext(to: *BoostContext, data: usize) callconv(.c) Transfer;

    extern fn ontop_fcontext(
        to: *BoostContext,
        data: usize,
        f: *const fn (t: Transfer) callconv(.c) Transfer,
    ) callconv(.c) Transfer;

    pub fn init(
        info: StackInfo,
        f: *const fn (t: Transfer) callconv(.c) noreturn,
    ) *BoostContext {
        return make_fcontext(info.start, info.reserved_size, f);
    }

    pub fn yieldTo(self: *BoostContext, data: usize) Transfer {
        return jump_fcontext(self, data);
    }

    pub fn yieldToOnTop(
        self: *BoostContext,
        data: usize,
        on_top: fn (t: Transfer) callconv(.c) Transfer,
    ) Transfer {
        return ontop_fcontext(self, data, on_top);
    }
};

// Derived from the Boost Context library:
// Copyright Edward Nevill + Oliver Kowalke 2015
// Distributed under the Boost Software License, Version 1.0.
//
// Boost Software License - Version 1.0 - August 17th, 2003
//
// Permission is hereby granted, free of charge, to any person or organization
// obtaining a copy of the software and accompanying documentation covered by
// this license (the "Software") to use, reproduce, display, distribute,
// execute, and transmit the Software, and to prepare derivative works of the
// Software, and to permit third-parties to whom the Software is furnished to
// do so, all subject to the following:
//
// The copyright notices in the Software and this entire statement, including
// the above license grant, this restriction and the following disclaimer,
// must be included in all copies of the Software, in whole or in part, and
// all derivative works of the Software, unless such copies or derivative
// works are solely in the form of machine-executable object code generated by
// a source language processor.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
// SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
// FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
// DEALINGS IN THE SOFTWARE.
const WindowsContextAarch64 = extern struct {
    d8: u64,
    d9: u64,
    d10: u64,
    d11: u64,
    d12: u64,
    d13: u64,
    d14: u64,
    d15: u64,
    x19: u64,
    x20: u64,
    x21: u64,
    x22: u64,
    x23: u64,
    x24: u64,
    x25: u64,
    x26: u64,
    x27: u64,
    x28: u64,
    fp: u64,
    lr: u64,
    stack_base: u64,
    stack_limit: u64,
    deallocation_stack: u64,
    fiber_data: u64,
    pc: u64,
    alignment: u64 = undefined,

    extern fn jump_fcontext(to: *WindowsContextAarch64, data: usize) callconv(.c) Transfer;

    extern fn ontop_fcontext(
        to: *WindowsContextAarch64,
        data: usize,
        f: *const fn (t: Transfer) callconv(.c) Transfer,
    ) callconv(.c) Transfer;

    pub fn init(
        info: StackInfo,
        f: *const fn (t: Transfer) callconv(.c) noreturn,
    ) callconv(.c) *WindowsContextAarch64 {
        @setRuntimeSafety(false);
        const context_end = std.mem.alignBackward(usize, @intFromPtr(info.start), 16);
        const context: *WindowsContextAarch64 = @ptrFromInt(context_end - @sizeOf(WindowsContextAarch64));
        context.stack_base = @intFromPtr(info.start);
        context.stack_limit = @intFromPtr(info.start - info.commited_size);
        context.deallocation_stack = @intFromPtr(info.start - info.reserved_size);
        context.fiber_storage = 0;

        context.x19 = @intFromPtr(f);
        context.pc = @intFromPtr(&trampoline);
        context.lr = @intFromPtr(&finish);

        return context;
    }

    pub fn yieldTo(self: *WindowsContextAarch64, data: usize) Transfer {
        return jump_fcontext(self, data);
    }

    pub fn yieldToOnTop(
        self: *WindowsContextAarch64,
        data: usize,
        on_top: fn (t: Transfer) callconv(.c) Transfer,
    ) Transfer {
        return ontop_fcontext(self, data, on_top);
    }

    fn trampoline() callconv(.naked) noreturn {
        @setRuntimeSafety(false);
        asm volatile (
            \\stp  fp, lr, [sp, #-0x10]!
            \\mov  fp, sp
            \\blr x19
        );
    }

    fn finish() callconv(.naked) noreturn {
        @setRuntimeSafety(false);
        asm volatile (
            \\// exit code is zero
            \\mov  x0, #0
            \\// exit application
            \\bl  _exit
        );
    }
};

// Derived from the Boost Context library:
// Copyright Oliver Kowalke 2009.
// Copyright Thomas Sailer 2013.
// Distributed under the Boost Software License, Version 1.0.
//
// Boost Software License - Version 1.0 - August 17th, 2003
//
// Permission is hereby granted, free of charge, to any person or organization
// obtaining a copy of the software and accompanying documentation covered by
// this license (the "Software") to use, reproduce, display, distribute,
// execute, and transmit the Software, and to prepare derivative works of the
// Software, and to permit third-parties to whom the Software is furnished to
// do so, all subject to the following:
//
// The copyright notices in the Software and this entire statement, including
// the above license grant, this restriction and the following disclaimer,
// must be included in all copies of the Software, in whole or in part, and
// all derivative works of the Software, unless such copies or derivative
// works are solely in the form of machine-executable object code generated by
// a source language processor.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
// SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
// FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
// DEALINGS IN THE SOFTWARE.
const WindowsContextX86_64 = extern struct {
    xmm6: u128,
    xmm7: u128,
    xmm8: u128,
    xmm9: u128,
    xmm10: u128,
    xmm11: u128,
    xmm12: u128,
    xmm13: u128,
    xmm14: u128,
    xmm15: u128,
    fc_mxcsr: u32,
    fc_x87_cw: u32,
    alignment: u64 = undefined,
    fiber_storage: u64,
    deallocation_stack: u64,
    stack_limit: u64,
    stack_base: u64,
    r12: u64,
    r13: u64,
    r14: u64,
    r15: u64,
    rdi: u64,
    rsi: u64,
    rbx: u64,
    rbp: u64,
    hidden: u64,
    rip: u64,
    parameters: [4]u64,
    transport: u64,
    data: u64,

    extern fn jump_fcontext(to: *WindowsContextX86_64, data: usize) callconv(.c) Transfer;

    extern fn ontop_fcontext(
        to: *WindowsContextX86_64,
        data: usize,
        f: *const fn (t: Transfer) callconv(.c) Transfer,
    ) callconv(.c) Transfer;

    pub fn init(
        info: StackInfo,
        f: *const fn (t: Transfer) callconv(.c) noreturn,
    ) callconv(.c) *WindowsContextX86_64 {
        @setRuntimeSafety(false);
        const context_end = std.mem.alignBackward(usize, @intFromPtr(info.start), 16);
        const context: *WindowsContextX86_64 = @ptrFromInt(context_end - @sizeOf(WindowsContextX86_64));
        context.rbx = @intFromPtr(f);
        context.stack_base = @intFromPtr(info.start);
        context.stack_limit = @intFromPtr(info.start - info.commited_size);
        context.deallocation_stack = @intFromPtr(info.start - info.reserved_size);
        context.fiber_storage = 0;

        asm volatile (
            \\/* save MMX control- and status-word */
            \\stmxcsr  0xa0(%rax)
            \\/* save x87 control-word */
            \\fnstcw   0xa4(%rax)
            :
            : [context] "{rax}" (context),
        );

        context.hidden = @intFromPtr(&context.transport);
        context.rip = @intFromPtr(&trampoline);
        context.rbp = @intFromPtr(&finish);

        return context;
    }

    pub fn yieldTo(self: *WindowsContextX86_64, data: usize) Transfer {
        return jump_fcontext(self, data);
    }

    pub fn yieldToOnTop(
        self: *WindowsContextX86_64,
        data: usize,
        on_top: fn (t: Transfer) callconv(.c) Transfer,
    ) Transfer {
        return ontop_fcontext(self, data, on_top);
    }

    fn trampoline() callconv(.naked) noreturn {
        @setRuntimeSafety(false);
        asm volatile (
            \\#store return address on stack */
            \\/* fix stack alignment */
            \\pushq %rbp
            \\/* jump to context-function */
            \\jmp *%rbx
        );
    }

    fn finish() callconv(.naked) noreturn {
        @setRuntimeSafety(false);
        asm volatile (
            \\/* 32byte shadow-space for _exit() */
            \\andq  $-32, %rsp
            \\/* 32byte shadow-space for _exit() are
            \\/* already reserved by make_fcontext() */
            \\/* exit code is zero */
            \\xorq  %rcx, %rcx
            \\/* exit application */
            \\call  _exit
            \\hlt
        );
    }
};

test "yield to context" {
    const stack = try std.testing.allocator.alloc(u8, 1024 * 3);
    defer std.testing.allocator.free(stack);

    const f = struct {
        fn f(t: Transfer) callconv(.c) noreturn {
            var tr = t;
            for (0..1000) |i| {
                tr = tr.context.yieldTo(i);
            }
            unreachable;
        }
    }.f;

    var t = Transfer{ .context = Context.init(.forSlice(stack), &f) };
    for (0..10) |i| {
        t = t.context.yieldTo(0);
        try std.testing.expectEqual(i, t.data);
    }
}

test "auto commit stack" {
    if (builtin.os.tag != .windows) return;

    var stack = try Stack.init(1024 * 1024 * 2);
    defer stack.deinit();

    try std.testing.expectEqual(stack.commited_size, std.heap.page_size_min);
    const f = struct {
        fn f(t: Transfer) callconv(.c) noreturn {
            const x = [_]u8{69} ** (1024 * 8);
            std.mem.doNotOptimizeAway(x);
            _ = t.context.yieldTo(0);
            unreachable;
        }
    }.f;

    var t = Transfer{ .context = Context.init(.forStack(stack), &f) };
    t = t.context.yieldTo(0);
    stack.updateCommitedSizeFromContext(t.context);
    try std.testing.expect(stack.commited_size > std.heap.page_size_min);
}

/// Data passed between contexts during a context switch.
pub const Transfer = extern struct {
    context: Context,
    data: usize = 0,
};

pub const Stack = struct {
    memory: []align(std.heap.page_size_min) u8,
    commited_size: if (builtin.os.tag == .windows) usize else void,

    pub fn init(size: usize) Allocator.Error!Stack {
        return StackAllocator.allocate(size);
    }

    pub fn deinit(self: Stack) void {
        StackAllocator.deallocate(self);
    }

    pub fn transitionCold(self: Stack) Stack {
        return StackAllocator.transitionCold(self);
    }

    pub fn updateCommitedSizeFromContext(self: *Stack, context: Context) void {
        if (builtin.os.tag == .windows) {
            std.debug.assert(@intFromPtr(self.memory.ptr) == context.ptr.deallocation_stack);
            std.debug.assert(self.memory.len == context.ptr.stack_base - context.ptr.deallocation_stack);
            self.commited_size = context.ptr.stack_base - context.ptr.stack_limit;
        }
    }
};

pub const StackAllocator = struct {
    var page_size_: std.atomic.Value(usize) = if (std.heap.page_size_min == std.heap.page_size_max)
        .init(std.heap.page_size_min)
    else
        .init(0);
    var min_stack_size_: std.atomic.Value(usize) = switch (builtin.os.tag) {
        .windows => if (builtin.cpu.arch == .x86) .init(4 * 1024) else .init(8 * 1024),
        else => .init(0),
    };
    var max_stack_size_: std.atomic.Value(usize) = switch (builtin.os.tag) {
        .windows => .init(std.math.maxInt(usize)),
        else => .init(0),
    };

    fn pageSize() usize {
        var size = page_size_.load(.monotonic);
        if (size != 0) return size;
        if (builtin.os.tag == .windows) unreachable;
        size = std.heap.pageSize();
        page_size_.store(size, .monotonic);
        return size;
    }

    pub fn minStackSize() usize {
        var size = min_stack_size_.load(.monotonic);
        if (size != 0) return size;

        if (builtin.os.tag == .windows) unreachable;
        size = pageSize();
        min_stack_size_.store(size, .monotonic);
        return size;
    }

    pub fn maxStackSize() usize {
        var size = max_stack_size_.load(.monotonic);
        if (size != 0) return size;

        if (builtin.os.tag == .windows) unreachable;
        const stack_limit = std.posix.getrlimit(.STACK) catch unreachable;
        if (stack_limit.max == std.c.RLIM.INFINITY or stack_limit.max >= std.math.maxInt(usize)) {
            size = std.math.maxInt(usize);
            max_stack_size_.store(size, .monotonic);
            return size;
        }

        size = @intCast(stack_limit.max);
        max_stack_size_.store(size, .monotonic);
        return size;
    }

    /// Allocates a new stack.
    fn allocate(size: usize) Allocator.Error!Stack {
        const page_size = pageSize();
        const min_stack_size = minStackSize();
        const pages = (@max(size, min_stack_size) + page_size - 1) / page_size;
        const rounded_size = (pages + 1) * page_size;

        const max_stack_size = maxStackSize();
        if (rounded_size > max_stack_size) return Allocator.Error.OutOfMemory;

        if (builtin.os.tag == .windows) {
            const memory: [*]align(std.heap.page_size_min) u8 = @ptrCast(@alignCast(std.os.windows.VirtualAlloc(
                null,
                rounded_size,
                std.os.windows.MEM_RESERVE,
                std.os.windows.PAGE_READWRITE,
            ) catch return Allocator.Error.OutOfMemory));
            errdefer std.os.windows.VirtualFree(memory, 0, std.os.windows.MEM_RELEASE);

            // Commit first two pages.
            const commited_memory = memory[rounded_size - 2 * page_size .. rounded_size];
            _ = std.os.windows.VirtualAlloc(
                commited_memory.ptr,
                commited_memory.len,
                std.os.windows.MEM_COMMIT,
                std.os.windows.PAGE_READWRITE,
            ) catch return Allocator.Error.OutOfMemory;

            // Protect last page.
            var old: std.os.windows.DWORD = undefined;
            std.os.windows.VirtualProtect(
                commited_memory.ptr,
                page_size,
                std.os.windows.PAGE_READWRITE | std.os.windows.PAGE_GUARD,
                &old,
            ) catch return Allocator.Error.OutOfMemory;
            return Stack{ .memory = memory[0..rounded_size], .commited_size = page_size };
        } else {
            const opt: std.posix.system.MAP = if (@hasField(std.posix.system.MAP, "STACK"))
                .{ .TYPE = .PRIVATE, .ANONYMOUS = true, .STACK = true }
            else
                .{ .TYPE = .PRIVATE, .ANONYMOUS = true };

            const memory = std.posix.mmap(
                null,
                rounded_size,
                std.posix.PROT.READ | std.posix.PROT.WRITE,
                opt,
                -1,
                0,
            ) catch return Allocator.Error.OutOfMemory;
            errdefer std.posix.munmap(memory);

            // Protect last page.
            std.posix.mprotect(
                memory[0..page_size],
                std.posix.PROT.NONE,
            ) catch return Allocator.Error.OutOfMemory;
            return Stack{ .memory = memory, .commited_size = {} };
        }
    }

    /// Deallocates a stack.
    pub fn deallocate(stack: Stack) void {
        if (builtin.os.tag == .windows) {
            std.os.windows.VirtualFree(stack.memory.ptr, 0, std.os.windows.MEM_RELEASE);
        } else {
            std.posix.munmap(stack.memory);
        }
    }

    /// Marks the stack memory as cold.
    ///
    /// Depending on the operating system, this function may decommit the stack memory.
    pub fn transitionCold(stack: Stack) Stack {
        if (builtin.os.tag == .windows) {
            var s = stack;
            const page_size = pageSize();
            const commited_memory = s.memory[s.memory.len - s.commited_size - page_size ..];
            const decommit_memory = commited_memory[0 .. commited_memory.len - 2 * page_size];
            const remaining_memory = commited_memory[decommit_memory.len..];
            if (decommit_memory.len == 0) return stack;
            std.debug.assert(remaining_memory.len == 2 * page_size);
            std.os.windows.VirtualFree(decommit_memory.ptr, decommit_memory.len, std.os.windows.MEM_DECOMMIT);

            // Protect last page.
            var old: std.os.windows.DWORD = undefined;
            std.os.windows.VirtualProtect(
                remaining_memory.ptr,
                page_size,
                std.os.windows.PAGE_READWRITE | std.os.windows.PAGE_GUARD,
                &old,
            ) catch unreachable;
            s.commited_size = page_size;
            return s;
        } else {
            std.posix.madvise(
                stack.memory.ptr,
                stack.memory.len,
                std.posix.MADV.DONTNEED,
            ) catch unreachable;
            return stack;
        }
    }
};

test "Stack: smoke test" {
    const stack = try Stack.init(1024 * 1024);
    defer stack.deinit();
    try std.testing.expect(stack.memory.len >= 1024 * 1024);
}
